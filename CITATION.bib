@article{autonomous_drifting_2024,
  title={Autonomous Vehicle Drifting: Comparing Control Strategies for Drift Maneuvers},
  author={Tehrani, Omeed and Contributors},
  journal={arXiv preprint},
  year={2024},
  note={Code available at \url{https://github.com/msuv08/autonomous-vehicle-drifting}},
  abstract={This work compares three control strategies for autonomous vehicle drift maneuvers: a model-based baseline controller, Inverse Kinodynamic Dynamics (IKD) with learned velocity correction, and Soft Actor-Critic (SAC) deep reinforcement learning. Results demonstrate that SAC achieves 49\% faster task completion (27 vs 53 steps) while maintaining 100\% success rate, significantly outperforming both baseline and IKD approaches. The IKD method achieves a modest 3.8\% improvement, validating that learned inverse dynamics can enhance model-based control. Our findings suggest that end-to-end reinforcement learning can discover superior trajectories compared to hand-engineered controllers for complex dynamic tasks.}
}

@misc{jake_deep_rl_algos,
  author={Lourie, Jake},
  title={Deep Reinforcement Learning Algorithms},
  year={2024},
  howpublished={\url{https://github.com/jakelourie1502/deep-rl-algos}},
  note={SAC implementation used in this work}
}
